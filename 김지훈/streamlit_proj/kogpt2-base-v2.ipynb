{"cells":[{"cell_type":"markdown","metadata":{"id":"9Iwa3a-ydx3z"},"source":["dataset"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5955,"status":"ok","timestamp":1674628355030,"user":{"displayName":"김지훈","userId":"08130216737598451536"},"user_tz":-540},"id":"uT_UwIOOcnCM","outputId":"3de04fc1-33b4-4daf-f8a1-07ef1c880d27"},"outputs":[],"source":["#pip install transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":15448,"status":"ok","timestamp":1674628370476,"user":{"displayName":"김지훈","userId":"08130216737598451536"},"user_tz":-540},"id":"_40NxplHdtg-"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\JIHOON\\Desktop\\study\\board\\daily_pj\\김지훈\\streamlit_proj\\stream_env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import math\n","import numpy as np\n","import pandas as pd\n","import random\n","import re\n","import torch\n","import urllib.request\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import PreTrainedTokenizerFast"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1674628370476,"user":{"displayName":"김지훈","userId":"08130216737598451536"},"user_tz":-540},"id":"lajXTrUWd8YX"},"outputs":[],"source":["def collate_batch(batch):\n","    data = [item[0] for item in batch]\n","    mask = [item[1] for item in batch]\n","    label = [item[2] for item in batch]\n","    return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":229},"executionInfo":{"elapsed":716,"status":"error","timestamp":1674628371184,"user":{"displayName":"김지훈","userId":"08130216737598451536"},"user_tz":-540},"id":"dJmzWM0Md9_P","outputId":"0ec7c7d9-16d9-4113-bfb0-71d3d7ee3e40"},"outputs":[],"source":["# train_set = ChatbotDataset(Chatbot_Data, max_len=40)\n","\n","# #윈도우 환경에서 num_workers 는 무조건 0으로 지정, 리눅스에서는 2\n","# train_dataloader = DataLoader(train_set, batch_size=32, num_workers=0, shuffle=True, collate_fn=collate_batch,)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"aborted","timestamp":1674628371185,"user":{"displayName":"김지훈","userId":"08130216737598451536"},"user_tz":-540},"id":"KCht7lKfd_BF"},"outputs":[],"source":["# print(\"start\")\n","# for batch_idx, samples in enumerate(train_dataloader):\n","#     token_ids, mask, label = samples\n","#     print(\"token_ids ====> \", token_ids)\n","#     print(\"mask =====> \", mask)\n","#     print(\"label =====> \", label)\n","# print(\"end\")"]},{"cell_type":"markdown","metadata":{"id":"X1TakpxXduqF"},"source":["kogpt"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":768,"status":"ok","timestamp":1674628417901,"user":{"displayName":"김지훈","userId":"08130216737598451536"},"user_tz":-540},"id":"L3pAdZ2OceU3"},"outputs":[],"source":["import torch\n","from transformers import GPT2LMHeadModel"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1674628441377,"user":{"displayName":"김지훈","userId":"08130216737598451536"},"user_tz":-540},"id":"4gK502RYdW67"},"outputs":[],"source":["Q_TKN = \"<usr>\"\n","A_TKN = \"<sys>\"\n","BOS = '</s>'\n","EOS = '</s>'\n","MASK = '<unused0>'\n","SENT = '<unused1>'\n","PAD = '<pad>'"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":653,"status":"ok","timestamp":1674628418553,"user":{"displayName":"김지훈","userId":"08130216737598451536"},"user_tz":-540},"id":"aCgsLGQFcx7O","outputId":"c5b711ef-e3df-4c7a-de45-d9e7c14e8b8d"},"outputs":[{"name":"stderr","output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n"]},{"data":{"text/plain":["['▁안녕',\n"," '하',\n"," '세',\n"," '요.',\n"," '▁한국어',\n"," '▁G',\n"," 'P',\n"," 'T',\n"," '-2',\n"," '▁입',\n"," '니다.',\n"," '😤',\n"," ':)',\n"," 'l^o']"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import PreTrainedTokenizerFast\n","tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\", bos_token='</s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>', mask_token='<mask>') \n","tokenizer.tokenize(\"안녕하세요. 한국어 GPT-2 입니다.😤:)l^o\")"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4689,"status":"ok","timestamp":1674628423241,"user":{"displayName":"김지훈","userId":"08130216737598451536"},"user_tz":-540},"id":"d9zbER_Hc7s9"},"outputs":[],"source":["model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9419,"status":"ok","timestamp":1674628432658,"user":{"displayName":"김지훈","userId":"08130216737598451536"},"user_tz":-540},"id":"hx20-h_idEpt","outputId":"f5fb3fdc-c4a5-4c97-f241-e7ed5fdf84c8"},"outputs":[{"name":"stdout","output_type":"stream","text":["운동 하려고 하는 것 같습니다.\n","그런데 이게 지금 현재로서는 굉장히 어려운 상황입니다.\n","왜냐하면 그~ 저희가 이제 뭐 여러 가지 얘기를 하고 있는데요.\n","이제 우리 국민들이 가장 많이 걱정하는 게 바로 이런 것들이거든요?\n","네. 그래서 우리가 좀 더 적극적으로 나서야 될 필요가 있다고 생각합니다.\n","예. 자 오늘 말씀 여기까지 듣겠습니다. 고맙고요\n","감사합니다.</d> 네 안녕하십니까?\n","시사탱크에 장성민 입니다.\n","오늘은 어떤 소식들 준비했습니까.\n","먼저 박근혜 대통령이 어제 청와대에서 열린 국무회의에서 세월호 참사에 대한 대국민 사과를 했죠.\n","\n"]}],"source":["text = '운동 하려고'\n","input_ids = tokenizer.encode(text)\n","gen_ids = model.generate(torch.tensor([input_ids]),\n","                           max_length=128,\n","                           repetition_penalty=2.0,\n","                           pad_token_id=tokenizer.pad_token_id,\n","                           eos_token_id=tokenizer.eos_token_id,\n","                           bos_token_id=tokenizer.bos_token_id,\n","                           use_cache=True)\n","generated = tokenizer.decode(gen_ids[0,:].tolist())\n","print(generated)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4701,"status":"ok","timestamp":1674628437350,"user":{"displayName":"김지훈","userId":"08130216737598451536"},"user_tz":-540},"id":"G5NKrWHCdQRZ","outputId":"1f9fe5e9-0d50-4a6b-b475-d857525dabe4"},"outputs":[],"source":["\n","#pip install pytorch_lightning"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":1454,"status":"ok","timestamp":1674628440102,"user":{"displayName":"김지훈","userId":"08130216737598451536"},"user_tz":-540},"id":"eg_3RlbBdIDG"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","from pytorch_lightning import Trainer\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","#from pytorch_lightning.core.lightning import LightningModule\n","from torch.utils.data import DataLoader, Dataset\n","from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n","from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n","import re"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5515,"status":"ok","timestamp":1674628447821,"user":{"displayName":"김지훈","userId":"08130216737598451536"},"user_tz":-540},"id":"ypPMx3CNdYat","outputId":"df83f7be-89f8-497c-8dca-cd64c62b8922"},"outputs":[{"name":"stderr","output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n"]}],"source":["koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n","            bos_token=BOS, eos_token=EOS, unk_token='<unk>',\n","            pad_token=PAD, mask_token=MASK) \n","model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":700,"status":"ok","timestamp":1674628449583,"user":{"displayName":"김지훈","userId":"08130216737598451536"},"user_tz":-540},"id":"jvei2sXLdZkZ","outputId":"b1dfacc5-3136-433e-9da6-46595a7e5e6c"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Q</th>\n","      <th>A</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4566</th>\n","      <td>층간소음 때문에 왜 살인이 나는지 알 거 같애</td>\n","      <td>일상을 침해당하기 때문이죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4088</th>\n","      <td>전화 안 받으니까 초조해져</td>\n","      <td>바쁜일이 있나봐요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10231</th>\n","      <td>썸 타는데 사랑하다고 말할 수 있음?</td>\n","      <td>좋아함을 점프했네요.</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>8024</th>\n","      <td>정말 끝이라고</td>\n","      <td>이별을 받아들이는 것도 중요해요.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>11329</th>\n","      <td>집착을 줄이고싶어.</td>\n","      <td>자신에게 더 집착해봐요.</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                               Q                   A  label\n","4566   층간소음 때문에 왜 살인이 나는지 알 거 같애     일상을 침해당하기 때문이죠.      0\n","4088              전화 안 받으니까 초조해져          바쁜일이 있나봐요.      0\n","10231       썸 타는데 사랑하다고 말할 수 있음?         좋아함을 점프했네요.      2\n","8024                     정말 끝이라고  이별을 받아들이는 것도 중요해요.      1\n","11329                 집착을 줄이고싶어.       자신에게 더 집착해봐요.      2"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["import urllib.request\n","\n","urllib.request.urlretrieve(\n","    \"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\",\n","    filename=\"ChatBotData.csv\",\n",")\n","Chatbot_Data = pd.read_csv(\"ChatBotData.csv\")\n","## Test 용으로 300개 데이터만 처리한다.\n","Chatbot_Data = Chatbot_Data.sample(frac=0.1)\n","Chatbot_Data.head()"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1674628370476,"user":{"displayName":"김지훈","userId":"08130216737598451536"},"user_tz":-540},"id":"z-HwxfJJd2Pr"},"outputs":[],"source":["class ChatbotDataset(Dataset):\n","    def __init__(self, chats, max_len=40):  # 데이터셋의 전처리를 해주는 부분\n","        self._data = chats\n","        self.max_len = max_len\n","        self.q_token = Q_TKN\n","        self.a_token = A_TKN\n","        self.sent_token = SENT\n","        self.eos = EOS\n","        self.mask = MASK\n","        self.tokenizer = koGPT2_TOKENIZER\n","\n","    def __len__(self):  # chatbotdata 의 길이를 리턴한다.\n","        return len(self._data)\n","\n","    def __getitem__(self, idx):  # 로드한 챗봇 데이터를 차례차례 DataLoader로 넘겨주는 메서드\n","        turn = self._data.iloc[idx]\n","        q = turn[\"Q\"]  # 질문을 가져온다.\n","        q = re.sub(r\"([?.!,])\", r\" \", q)  # 구둣점들을 제거한다.\n","\n","        a = turn[\"A\"]  # 답변을 가져온다.\n","        a = re.sub(r\"([?.!,])\", r\" \", a)  # 구둣점들을 제거한다.\n","\n","        q_toked = self.tokenizer.tokenize(self.q_token + q + self.sent_token)\n","        q_len = len(q_toked)\n","\n","        a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos)\n","        a_len = len(a_toked)\n","\n","        #질문의 길이가 최대길이보다 크면\n","        if q_len > self.max_len:\n","            a_len = self.max_len - q_len        #답변의 길이를 최대길이 - 질문길이\n","            if a_len <= 0:       #질문의 길이가 너무 길어 질문만으로 최대 길이를 초과 한다면\n","                q_toked = q_toked[-(int(self.max_len / 2)) :]   #질문길이를 최대길이의 반으로 \n","                q_len = len(q_toked)\n","                a_len = self.max_len - q_len              #답변의 길이를 최대길이 - 질문길이\n","            a_toked = a_toked[:a_len]\n","            a_len = len(a_toked)\n","\n","        #질문의 길이 + 답변의 길이가 최대길이보다 크면\n","        if q_len + a_len > self.max_len:\n","            a_len = self.max_len - q_len        #답변의 길이를 최대길이 - 질문길이\n","            if a_len <= 0:       #질문의 길이가 너무 길어 질문만으로 최대 길이를 초과 한다면\n","                q_toked = q_toked[-(int(self.max_len / 2)) :]   #질문길이를 최대길이의 반으로 \n","                q_len = len(q_toked)\n","                a_len = self.max_len - q_len              #답변의 길이를 최대길이 - 질문길이\n","            a_toked = a_toked[:a_len]\n","            a_len = len(a_toked)\n","\n","        # 답변 labels = [mask, mask, ...., mask, ..., <bos>,..답변.. <eos>, <pad>....]\n","        labels = [self.mask,] * q_len + a_toked[1:]\n","\n","        # mask = 질문길이 0 + 답변길이 1 + 나머지 0\n","        mask = [0] * q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len)\n","        # 답변 labels을 index 로 만든다.\n","        labels_ids = self.tokenizer.convert_tokens_to_ids(labels)\n","        # 최대길이만큼 PADDING\n","        while len(labels_ids) < self.max_len:\n","            labels_ids += [self.tokenizer.pad_token_id]\n","\n","        # 질문 + 답변을 index 로 만든다.    \n","        token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\n","        # 최대길이만큼 PADDING\n","        while len(token_ids) < self.max_len:\n","            token_ids += [self.tokenizer.pad_token_id]\n","\n","        #질문+답변, 마스크, 답변\n","        return (token_ids, np.array(mask), labels_ids)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["True"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.is_available()\n","#torch.__version__\n"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":358,"status":"ok","timestamp":1674628452783,"user":{"displayName":"김지훈","userId":"08130216737598451536"},"user_tz":-540},"id":"EYC4Pg-fddnz"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","train_set = ChatbotDataset(Chatbot_Data, max_len=40)\n","#윈도우 환경에서 num_workers 는 무조건 0으로 지정, 리눅스에서는 2\n","train_dataloader = DataLoader(train_set, batch_size=16, num_workers=0, shuffle=True, collate_fn=collate_batch,)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":273,"status":"ok","timestamp":1674628454060,"user":{"displayName":"김지훈","userId":"08130216737598451536"},"user_tz":-540},"id":"9GsK1EGgeE3N","outputId":"147b9bc8-5c83-4c78-f54e-cb0b98c71552"},"outputs":[{"data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(51200, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",")"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["\n","model.to(device)\n","model.train()"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":246,"status":"ok","timestamp":1674628456507,"user":{"displayName":"김지훈","userId":"08130216737598451536"},"user_tz":-540},"id":"UBwTSr5ReGf-"},"outputs":[],"source":["learning_rate = 3e-5\n","criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","epoch = 10\n","Sneg = -1e18"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lLj6pkbIeJH0","outputId":"ef7376a3-8970-471e-eb36-c5302292b15d"},"outputs":[{"name":"stdout","output_type":"stream","text":["start\n","0\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\JIHOON\\AppData\\Local\\Temp\\ipykernel_10712\\2495599640.py:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 │   │   </span>out = out.logits      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">#Returns a new tensor with the logit of the elements of in</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12 │   │   </span>mask_3d = mask.unsqueeze(dim=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>).repeat_interleave(repeats=out.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>], dim=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>)      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 │   │   </span>mask_out = torch.where(mask_3d == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, out, Sneg * torch.ones_like(out))              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>14 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>loss = criterion(mask_out.transpose(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>), label)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 │   │   # 평균 loss 만들기 avg_loss[0] / avg_loss[1] &lt;- loss 정규화</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16 │   │   </span>avg_loss = loss.sum() / mask.sum()                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">17 │   │   </span>avg_loss.backward()                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\JIHOON\\Desktop\\study\\board\\daily_pj\\김지훈\\streamlit_proj\\stream_env\\lib\\site-packages\\</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">torch\\nn\\modules\\module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1194</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 │   │   # this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\JIHOON\\Desktop\\study\\board\\daily_pj\\김지훈\\streamlit_proj\\stream_env\\lib\\site-packages\\</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">torch\\nn\\modules\\loss.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1174</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1171 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.label_smoothing = label_smoothing                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1172 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1173 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor, target: Tensor) -&gt; Tensor:                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1174 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> F.cross_entropy(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, target, weight=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight,                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1175 │   │   │   │   │   │   │      </span>ignore_index=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ignore_index, reduction=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.reduction,  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1176 │   │   │   │   │   │   │      </span>label_smoothing=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.label_smoothing)                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1177 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\JIHOON\\Desktop\\study\\board\\daily_pj\\김지훈\\streamlit_proj\\stream_env\\lib\\site-packages\\</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">torch\\nn\\functional.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3026</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cross_entropy</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3023 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3024 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> size_average <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> reduce <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3025 │   │   </span>reduction = _Reduction.legacy_get_string(size_average, reduce)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3026 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> torch._C._nn.cross_entropy_loss(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, target, weight, _Reduction.get_enum(re  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3027 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3028 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3029 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">binary_cross_entropy</span>(                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n","<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>Expected all tensors to be on the same device, but found at least two devices, cu<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">da:0</span> and cpu! <span style=\"font-weight: bold\">(</span>when \n","checking argument for argument target in method wrapper__nll_loss2d_forward<span style=\"font-weight: bold\">)</span>\n","</pre>\n"],"text/plain":["\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m11 \u001b[0m\u001b[2m│   │   \u001b[0mout = out.logits      \u001b[2m#Returns a new tensor with the logit of the elements of in\u001b[0m    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m12 \u001b[0m\u001b[2m│   │   \u001b[0mmask_3d = mask.unsqueeze(dim=\u001b[94m2\u001b[0m).repeat_interleave(repeats=out.shape[\u001b[94m2\u001b[0m], dim=\u001b[94m2\u001b[0m)      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m13 \u001b[0m\u001b[2m│   │   \u001b[0mmask_out = torch.where(mask_3d == \u001b[94m1\u001b[0m, out, Sneg * torch.ones_like(out))              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m14 \u001b[2m│   │   \u001b[0mloss = criterion(mask_out.transpose(\u001b[94m2\u001b[0m, \u001b[94m1\u001b[0m), label)                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# 평균 loss 만들기 avg_loss[0] / avg_loss[1] <- loss 정규화\u001b[0m                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m16 \u001b[0m\u001b[2m│   │   \u001b[0mavg_loss = loss.sum() / mask.sum()                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m17 \u001b[0m\u001b[2m│   │   \u001b[0mavg_loss.backward()                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\JIHOON\\Desktop\\study\\board\\daily_pj\\김지훈\\streamlit_proj\\stream_env\\lib\\site-packages\\\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[33mtorch\\nn\\modules\\module.py\u001b[0m:\u001b[94m1194\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1194 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\JIHOON\\Desktop\\study\\board\\daily_pj\\김지훈\\streamlit_proj\\stream_env\\lib\\site-packages\\\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[33mtorch\\nn\\modules\\loss.py\u001b[0m:\u001b[94m1174\u001b[0m in \u001b[92mforward\u001b[0m                                                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1171 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.label_smoothing = label_smoothing                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1172 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1173 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor, target: Tensor) -> Tensor:                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1174 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m F.cross_entropy(\u001b[96minput\u001b[0m, target, weight=\u001b[96mself\u001b[0m.weight,                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1175 \u001b[0m\u001b[2m│   │   │   │   │   │   │      \u001b[0mignore_index=\u001b[96mself\u001b[0m.ignore_index, reduction=\u001b[96mself\u001b[0m.reduction,  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1176 \u001b[0m\u001b[2m│   │   │   │   │   │   │      \u001b[0mlabel_smoothing=\u001b[96mself\u001b[0m.label_smoothing)                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1177 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\JIHOON\\Desktop\\study\\board\\daily_pj\\김지훈\\streamlit_proj\\stream_env\\lib\\site-packages\\\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[33mtorch\\nn\\functional.py\u001b[0m:\u001b[94m3026\u001b[0m in \u001b[92mcross_entropy\u001b[0m                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3023 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3024 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m size_average \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mor\u001b[0m reduce \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3025 \u001b[0m\u001b[2m│   │   \u001b[0mreduction = _Reduction.legacy_get_string(size_average, reduce)                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3026 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m torch._C._nn.cross_entropy_loss(\u001b[96minput\u001b[0m, target, weight, _Reduction.get_enum(re  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3027 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3028 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m3029 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mbinary_cross_entropy\u001b[0m(                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n","\u001b[1;91mRuntimeError: \u001b[0mExpected all tensors to be on the same device, but found at least two devices, cu\u001b[1;92mda:0\u001b[0m and cpu! \u001b[1m(\u001b[0mwhen \n","checking argument for argument target in method wrapper__nll_loss2d_forward\u001b[1m)\u001b[0m\n"]},"metadata":{},"output_type":"display_data"}],"source":["print (\"start\")\n","for epoch in range(epoch):\n","    print(f'{epoch}')\n","    torch.cuda.empty_cache()\n","    for batch_idx, samples in enumerate(train_dataloader):\n","        optimizer.zero_grad()\n","        token_ids, mask, label = samples\n","        token_ids = token_ids.cuda()\n","        mask = mask.cuda()\n","        label = label.cuda()\n","        out = model(token_ids)\n","        out = out.logits      #Returns a new tensor with the logit of the elements of input\n","        mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n","        mask_out = torch.where(mask_3d == 1, out, Sneg * torch.ones_like(out))\n","        loss = criterion(mask_out.transpose(2, 1), label)\n","        # 평균 loss 만들기 avg_loss[0] / avg_loss[1] <- loss 정규화\n","        avg_loss = loss.sum() / mask.sum()\n","        avg_loss.backward()\n","        # 학습 끝\n","        optimizer.step()\n","print (\"end\")"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":2,"status":"aborted","timestamp":1674628371456,"user":{"displayName":"김지훈","userId":"08130216737598451536"},"user_tz":-540},"id":"iofxgCbweLKf"},"outputs":[],"source":["torch.save(model, \"model20\")"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["model = torch.load(\".\\model20\")"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["with torch.no_grad():\n","    while 1:\n","        q = input(\"user > \").strip()\n","        if q == \"quit\":\n","            break\n","        a = \"\"\n","        while 1:\n","            input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(Q_TKN + q + SENT + A_TKN + a)).unsqueeze(dim=0)\n","            pred = model(input_ids)\n","            pred = pred.logits\n","            gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().numpy().tolist())[-1]\n","            if gen == EOS:\n","                break\n","            a += gen.replace(\"▁\", \" \")\n","        print(\"Chatbot > {}\".format(a.strip()))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNXwVr7gtq5QnQqClM4exhG","provenance":[]},"kernelspec":{"display_name":"stream_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"},"vscode":{"interpreter":{"hash":"28620e9ee99261c21df2ec0c283daac7616764567eb7af53527c6a710e77d996"}}},"nbformat":4,"nbformat_minor":0}
