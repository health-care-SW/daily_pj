{"cells":[{"cell_type":"markdown","metadata":{"id":"9Iwa3a-ydx3z"},"source":["dataset"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5955,"status":"ok","timestamp":1674628355030,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"uT_UwIOOcnCM","outputId":"3de04fc1-33b4-4daf-f8a1-07ef1c880d27"},"outputs":[],"source":["#pip install transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":15448,"status":"ok","timestamp":1674628370476,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"_40NxplHdtg-"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\JIHOON\\Desktop\\study\\board\\daily_pj\\ê¹€ì§€í›ˆ\\streamlit_proj\\stream_env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import math\n","import numpy as np\n","import pandas as pd\n","import random\n","import re\n","import torch\n","import urllib.request\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import PreTrainedTokenizerFast"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1674628370476,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"lajXTrUWd8YX"},"outputs":[],"source":["def collate_batch(batch):\n","    data = [item[0] for item in batch]\n","    mask = [item[1] for item in batch]\n","    label = [item[2] for item in batch]\n","    return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":229},"executionInfo":{"elapsed":716,"status":"error","timestamp":1674628371184,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"dJmzWM0Md9_P","outputId":"0ec7c7d9-16d9-4113-bfb0-71d3d7ee3e40"},"outputs":[],"source":["# train_set = ChatbotDataset(Chatbot_Data, max_len=40)\n","\n","# #ìœˆë„ìš° í™˜ê²½ì—ì„œ num_workers ëŠ” ë¬´ì¡°ê±´ 0ìœ¼ë¡œ ì§€ì •, ë¦¬ëˆ…ìŠ¤ì—ì„œëŠ” 2\n","# train_dataloader = DataLoader(train_set, batch_size=32, num_workers=0, shuffle=True, collate_fn=collate_batch,)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"aborted","timestamp":1674628371185,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"KCht7lKfd_BF"},"outputs":[],"source":["# print(\"start\")\n","# for batch_idx, samples in enumerate(train_dataloader):\n","#     token_ids, mask, label = samples\n","#     print(\"token_ids ====> \", token_ids)\n","#     print(\"mask =====> \", mask)\n","#     print(\"label =====> \", label)\n","# print(\"end\")"]},{"cell_type":"markdown","metadata":{"id":"X1TakpxXduqF"},"source":["kogpt"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":768,"status":"ok","timestamp":1674628417901,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"L3pAdZ2OceU3"},"outputs":[],"source":["import torch\n","from transformers import GPT2LMHeadModel"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1674628441377,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"4gK502RYdW67"},"outputs":[],"source":["Q_TKN = \"<usr>\"\n","A_TKN = \"<sys>\"\n","BOS = '</s>'\n","EOS = '</s>'\n","MASK = '<unused0>'\n","SENT = '<unused1>'\n","PAD = '<pad>'"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":653,"status":"ok","timestamp":1674628418553,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"aCgsLGQFcx7O","outputId":"c5b711ef-e3df-4c7a-de45-d9e7c14e8b8d"},"outputs":[{"name":"stderr","output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n"]},{"data":{"text/plain":["['â–ì•ˆë…•',\n"," 'í•˜',\n"," 'ì„¸',\n"," 'ìš”.',\n"," 'â–í•œêµ­ì–´',\n"," 'â–G',\n"," 'P',\n"," 'T',\n"," '-2',\n"," 'â–ì…',\n"," 'ë‹ˆë‹¤.',\n"," 'ğŸ˜¤',\n"," ':)',\n"," 'l^o']"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import PreTrainedTokenizerFast\n","tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\", bos_token='</s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>', mask_token='<mask>') \n","tokenizer.tokenize(\"ì•ˆë…•í•˜ì„¸ìš”. í•œêµ­ì–´ GPT-2 ì…ë‹ˆë‹¤.ğŸ˜¤:)l^o\")"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4689,"status":"ok","timestamp":1674628423241,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"d9zbER_Hc7s9"},"outputs":[],"source":["model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9419,"status":"ok","timestamp":1674628432658,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"hx20-h_idEpt","outputId":"f5fb3fdc-c4a5-4c97-f241-e7ed5fdf84c8"},"outputs":[{"name":"stdout","output_type":"stream","text":["ìš´ë™ í•˜ë ¤ê³  í•˜ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤.\n","ê·¸ëŸ°ë° ì´ê²Œ ì§€ê¸ˆ í˜„ì¬ë¡œì„œëŠ” êµ‰ì¥íˆ ì–´ë ¤ìš´ ìƒí™©ì…ë‹ˆë‹¤.\n","ì™œëƒí•˜ë©´ ê·¸~ ì €í¬ê°€ ì´ì œ ë­ ì—¬ëŸ¬ ê°€ì§€ ì–˜ê¸°ë¥¼ í•˜ê³  ìˆëŠ”ë°ìš”.\n","ì´ì œ ìš°ë¦¬ êµ­ë¯¼ë“¤ì´ ê°€ì¥ ë§ì´ ê±±ì •í•˜ëŠ” ê²Œ ë°”ë¡œ ì´ëŸ° ê²ƒë“¤ì´ê±°ë“ ìš”?\n","ë„¤. ê·¸ë˜ì„œ ìš°ë¦¬ê°€ ì¢€ ë” ì ê·¹ì ìœ¼ë¡œ ë‚˜ì„œì•¼ ë  í•„ìš”ê°€ ìˆë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤.\n","ì˜ˆ. ì ì˜¤ëŠ˜ ë§ì”€ ì—¬ê¸°ê¹Œì§€ ë“£ê² ìŠµë‹ˆë‹¤. ê³ ë§™ê³ ìš”\n","ê°ì‚¬í•©ë‹ˆë‹¤.</d> ë„¤ ì•ˆë…•í•˜ì‹­ë‹ˆê¹Œ?\n","ì‹œì‚¬íƒ±í¬ì— ì¥ì„±ë¯¼ ì…ë‹ˆë‹¤.\n","ì˜¤ëŠ˜ì€ ì–´ë–¤ ì†Œì‹ë“¤ ì¤€ë¹„í–ˆìŠµë‹ˆê¹Œ.\n","ë¨¼ì € ë°•ê·¼í˜œ ëŒ€í†µë ¹ì´ ì–´ì œ ì²­ì™€ëŒ€ì—ì„œ ì—´ë¦° êµ­ë¬´íšŒì˜ì—ì„œ ì„¸ì›”í˜¸ ì°¸ì‚¬ì— ëŒ€í•œ ëŒ€êµ­ë¯¼ ì‚¬ê³¼ë¥¼ í–ˆì£ .\n","\n"]}],"source":["text = 'ìš´ë™ í•˜ë ¤ê³ '\n","input_ids = tokenizer.encode(text)\n","gen_ids = model.generate(torch.tensor([input_ids]),\n","                           max_length=128,\n","                           repetition_penalty=2.0,\n","                           pad_token_id=tokenizer.pad_token_id,\n","                           eos_token_id=tokenizer.eos_token_id,\n","                           bos_token_id=tokenizer.bos_token_id,\n","                           use_cache=True)\n","generated = tokenizer.decode(gen_ids[0,:].tolist())\n","print(generated)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4701,"status":"ok","timestamp":1674628437350,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"G5NKrWHCdQRZ","outputId":"1f9fe5e9-0d50-4a6b-b475-d857525dabe4"},"outputs":[],"source":["\n","#pip install pytorch_lightning"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":1454,"status":"ok","timestamp":1674628440102,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"eg_3RlbBdIDG"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","from pytorch_lightning import Trainer\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","#from pytorch_lightning.core.lightning import LightningModule\n","from torch.utils.data import DataLoader, Dataset\n","from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n","from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n","import re"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5515,"status":"ok","timestamp":1674628447821,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"ypPMx3CNdYat","outputId":"df83f7be-89f8-497c-8dca-cd64c62b8922"},"outputs":[{"name":"stderr","output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n"]}],"source":["koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n","            bos_token=BOS, eos_token=EOS, unk_token='<unk>',\n","            pad_token=PAD, mask_token=MASK) \n","model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":700,"status":"ok","timestamp":1674628449583,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"jvei2sXLdZkZ","outputId":"b1dfacc5-3136-433e-9da6-46595a7e5e6c"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Q</th>\n","      <th>A</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4566</th>\n","      <td>ì¸µê°„ì†ŒìŒ ë•Œë¬¸ì— ì™œ ì‚´ì¸ì´ ë‚˜ëŠ”ì§€ ì•Œ ê±° ê°™ì• </td>\n","      <td>ì¼ìƒì„ ì¹¨í•´ë‹¹í•˜ê¸° ë•Œë¬¸ì´ì£ .</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4088</th>\n","      <td>ì „í™” ì•ˆ ë°›ìœ¼ë‹ˆê¹Œ ì´ˆì¡°í•´ì ¸</td>\n","      <td>ë°”ìœì¼ì´ ìˆë‚˜ë´ìš”.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10231</th>\n","      <td>ì¸ íƒ€ëŠ”ë° ì‚¬ë‘í•˜ë‹¤ê³  ë§í•  ìˆ˜ ìˆìŒ?</td>\n","      <td>ì¢‹ì•„í•¨ì„ ì í”„í–ˆë„¤ìš”.</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>8024</th>\n","      <td>ì •ë§ ëì´ë¼ê³ </td>\n","      <td>ì´ë³„ì„ ë°›ì•„ë“¤ì´ëŠ” ê²ƒë„ ì¤‘ìš”í•´ìš”.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>11329</th>\n","      <td>ì§‘ì°©ì„ ì¤„ì´ê³ ì‹¶ì–´.</td>\n","      <td>ìì‹ ì—ê²Œ ë” ì§‘ì°©í•´ë´ìš”.</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                               Q                   A  label\n","4566   ì¸µê°„ì†ŒìŒ ë•Œë¬¸ì— ì™œ ì‚´ì¸ì´ ë‚˜ëŠ”ì§€ ì•Œ ê±° ê°™ì•      ì¼ìƒì„ ì¹¨í•´ë‹¹í•˜ê¸° ë•Œë¬¸ì´ì£ .      0\n","4088              ì „í™” ì•ˆ ë°›ìœ¼ë‹ˆê¹Œ ì´ˆì¡°í•´ì ¸          ë°”ìœì¼ì´ ìˆë‚˜ë´ìš”.      0\n","10231       ì¸ íƒ€ëŠ”ë° ì‚¬ë‘í•˜ë‹¤ê³  ë§í•  ìˆ˜ ìˆìŒ?         ì¢‹ì•„í•¨ì„ ì í”„í–ˆë„¤ìš”.      2\n","8024                     ì •ë§ ëì´ë¼ê³   ì´ë³„ì„ ë°›ì•„ë“¤ì´ëŠ” ê²ƒë„ ì¤‘ìš”í•´ìš”.      1\n","11329                 ì§‘ì°©ì„ ì¤„ì´ê³ ì‹¶ì–´.       ìì‹ ì—ê²Œ ë” ì§‘ì°©í•´ë´ìš”.      2"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["import urllib.request\n","\n","urllib.request.urlretrieve(\n","    \"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\",\n","    filename=\"ChatBotData.csv\",\n",")\n","Chatbot_Data = pd.read_csv(\"ChatBotData.csv\")\n","## Test ìš©ìœ¼ë¡œ 300ê°œ ë°ì´í„°ë§Œ ì²˜ë¦¬í•œë‹¤.\n","Chatbot_Data = Chatbot_Data.sample(frac=0.1)\n","Chatbot_Data.head()"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1674628370476,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"z-HwxfJJd2Pr"},"outputs":[],"source":["class ChatbotDataset(Dataset):\n","    def __init__(self, chats, max_len=40):  # ë°ì´í„°ì…‹ì˜ ì „ì²˜ë¦¬ë¥¼ í•´ì£¼ëŠ” ë¶€ë¶„\n","        self._data = chats\n","        self.max_len = max_len\n","        self.q_token = Q_TKN\n","        self.a_token = A_TKN\n","        self.sent_token = SENT\n","        self.eos = EOS\n","        self.mask = MASK\n","        self.tokenizer = koGPT2_TOKENIZER\n","\n","    def __len__(self):  # chatbotdata ì˜ ê¸¸ì´ë¥¼ ë¦¬í„´í•œë‹¤.\n","        return len(self._data)\n","\n","    def __getitem__(self, idx):  # ë¡œë“œí•œ ì±—ë´‡ ë°ì´í„°ë¥¼ ì°¨ë¡€ì°¨ë¡€ DataLoaderë¡œ ë„˜ê²¨ì£¼ëŠ” ë©”ì„œë“œ\n","        turn = self._data.iloc[idx]\n","        q = turn[\"Q\"]  # ì§ˆë¬¸ì„ ê°€ì ¸ì˜¨ë‹¤.\n","        q = re.sub(r\"([?.!,])\", r\" \", q)  # êµ¬ë‘£ì ë“¤ì„ ì œê±°í•œë‹¤.\n","\n","        a = turn[\"A\"]  # ë‹µë³€ì„ ê°€ì ¸ì˜¨ë‹¤.\n","        a = re.sub(r\"([?.!,])\", r\" \", a)  # êµ¬ë‘£ì ë“¤ì„ ì œê±°í•œë‹¤.\n","\n","        q_toked = self.tokenizer.tokenize(self.q_token + q + self.sent_token)\n","        q_len = len(q_toked)\n","\n","        a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos)\n","        a_len = len(a_toked)\n","\n","        #ì§ˆë¬¸ì˜ ê¸¸ì´ê°€ ìµœëŒ€ê¸¸ì´ë³´ë‹¤ í¬ë©´\n","        if q_len > self.max_len:\n","            a_len = self.max_len - q_len        #ë‹µë³€ì˜ ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ - ì§ˆë¬¸ê¸¸ì´\n","            if a_len <= 0:       #ì§ˆë¬¸ì˜ ê¸¸ì´ê°€ ë„ˆë¬´ ê¸¸ì–´ ì§ˆë¬¸ë§Œìœ¼ë¡œ ìµœëŒ€ ê¸¸ì´ë¥¼ ì´ˆê³¼ í•œë‹¤ë©´\n","                q_toked = q_toked[-(int(self.max_len / 2)) :]   #ì§ˆë¬¸ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ì˜ ë°˜ìœ¼ë¡œ \n","                q_len = len(q_toked)\n","                a_len = self.max_len - q_len              #ë‹µë³€ì˜ ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ - ì§ˆë¬¸ê¸¸ì´\n","            a_toked = a_toked[:a_len]\n","            a_len = len(a_toked)\n","\n","        #ì§ˆë¬¸ì˜ ê¸¸ì´ + ë‹µë³€ì˜ ê¸¸ì´ê°€ ìµœëŒ€ê¸¸ì´ë³´ë‹¤ í¬ë©´\n","        if q_len + a_len > self.max_len:\n","            a_len = self.max_len - q_len        #ë‹µë³€ì˜ ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ - ì§ˆë¬¸ê¸¸ì´\n","            if a_len <= 0:       #ì§ˆë¬¸ì˜ ê¸¸ì´ê°€ ë„ˆë¬´ ê¸¸ì–´ ì§ˆë¬¸ë§Œìœ¼ë¡œ ìµœëŒ€ ê¸¸ì´ë¥¼ ì´ˆê³¼ í•œë‹¤ë©´\n","                q_toked = q_toked[-(int(self.max_len / 2)) :]   #ì§ˆë¬¸ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ì˜ ë°˜ìœ¼ë¡œ \n","                q_len = len(q_toked)\n","                a_len = self.max_len - q_len              #ë‹µë³€ì˜ ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ - ì§ˆë¬¸ê¸¸ì´\n","            a_toked = a_toked[:a_len]\n","            a_len = len(a_toked)\n","\n","        # ë‹µë³€ labels = [mask, mask, ...., mask, ..., <bos>,..ë‹µë³€.. <eos>, <pad>....]\n","        labels = [self.mask,] * q_len + a_toked[1:]\n","\n","        # mask = ì§ˆë¬¸ê¸¸ì´ 0 + ë‹µë³€ê¸¸ì´ 1 + ë‚˜ë¨¸ì§€ 0\n","        mask = [0] * q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len)\n","        # ë‹µë³€ labelsì„ index ë¡œ ë§Œë“ ë‹¤.\n","        labels_ids = self.tokenizer.convert_tokens_to_ids(labels)\n","        # ìµœëŒ€ê¸¸ì´ë§Œí¼ PADDING\n","        while len(labels_ids) < self.max_len:\n","            labels_ids += [self.tokenizer.pad_token_id]\n","\n","        # ì§ˆë¬¸ + ë‹µë³€ì„ index ë¡œ ë§Œë“ ë‹¤.    \n","        token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\n","        # ìµœëŒ€ê¸¸ì´ë§Œí¼ PADDING\n","        while len(token_ids) < self.max_len:\n","            token_ids += [self.tokenizer.pad_token_id]\n","\n","        #ì§ˆë¬¸+ë‹µë³€, ë§ˆìŠ¤í¬, ë‹µë³€\n","        return (token_ids, np.array(mask), labels_ids)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["True"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.is_available()\n","#torch.__version__\n"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":358,"status":"ok","timestamp":1674628452783,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"EYC4Pg-fddnz"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","train_set = ChatbotDataset(Chatbot_Data, max_len=40)\n","#ìœˆë„ìš° í™˜ê²½ì—ì„œ num_workers ëŠ” ë¬´ì¡°ê±´ 0ìœ¼ë¡œ ì§€ì •, ë¦¬ëˆ…ìŠ¤ì—ì„œëŠ” 2\n","train_dataloader = DataLoader(train_set, batch_size=16, num_workers=0, shuffle=True, collate_fn=collate_batch,)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":273,"status":"ok","timestamp":1674628454060,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"9GsK1EGgeE3N","outputId":"147b9bc8-5c83-4c78-f54e-cb0b98c71552"},"outputs":[{"data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(51200, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",")"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["\n","model.to(device)\n","model.train()"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":246,"status":"ok","timestamp":1674628456507,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"UBwTSr5ReGf-"},"outputs":[],"source":["learning_rate = 3e-5\n","criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","epoch = 10\n","Sneg = -1e18"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lLj6pkbIeJH0","outputId":"ef7376a3-8970-471e-eb36-c5302292b15d"},"outputs":[{"name":"stdout","output_type":"stream","text":["start\n","0\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\JIHOON\\AppData\\Local\\Temp\\ipykernel_10712\\2495599640.py:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 â”‚   â”‚   </span>out = out.logits      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">#Returns a new tensor with the logit of the elements of in</span>    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12 â”‚   â”‚   </span>mask_3d = mask.unsqueeze(dim=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>).repeat_interleave(repeats=out.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>], dim=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>)      <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 â”‚   â”‚   </span>mask_out = torch.where(mask_3d == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, out, Sneg * torch.ones_like(out))              <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>14 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   </span>loss = criterion(mask_out.transpose(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>), label)                                   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 â”‚   â”‚   # í‰ê·  loss ë§Œë“¤ê¸° avg_loss[0] / avg_loss[1] &lt;- loss ì •ê·œí™”</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16 â”‚   â”‚   </span>avg_loss = loss.sum() / mask.sum()                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">17 â”‚   â”‚   </span>avg_loss.backward()                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\JIHOON\\Desktop\\study\\board\\daily_pj\\ê¹€ì§€í›ˆ\\streamlit_proj\\stream_env\\lib\\site-packages\\</span> <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #808000; text-decoration-color: #808000\">torch\\nn\\modules\\module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1194</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 â”‚   â”‚   # this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 â”‚   â”‚   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 â”‚   â”‚   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\JIHOON\\Desktop\\study\\board\\daily_pj\\ê¹€ì§€í›ˆ\\streamlit_proj\\stream_env\\lib\\site-packages\\</span> <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #808000; text-decoration-color: #808000\">torch\\nn\\modules\\loss.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1174</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                         <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1171 â”‚   â”‚   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.label_smoothing = label_smoothing                                            <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1172 â”‚   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1173 â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor, target: Tensor) -&gt; Tensor:                           <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>1174 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> F.cross_entropy(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, target, weight=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight,                         <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1175 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚      </span>ignore_index=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ignore_index, reduction=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.reduction,  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1176 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚      </span>label_smoothing=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.label_smoothing)                      <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1177 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\JIHOON\\Desktop\\study\\board\\daily_pj\\ê¹€ì§€í›ˆ\\streamlit_proj\\stream_env\\lib\\site-packages\\</span> <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #808000; text-decoration-color: #808000\">torch\\nn\\functional.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3026</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cross_entropy</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3023 â”‚   â”‚   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3024 â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> size_average <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> reduce <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3025 â”‚   â”‚   </span>reduction = _Reduction.legacy_get_string(size_average, reduce)                    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>3026 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> torch._C._nn.cross_entropy_loss(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, target, weight, _Reduction.get_enum(re  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3027 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3028 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3029 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">binary_cross_entropy</span>(                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n","<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>Expected all tensors to be on the same device, but found at least two devices, cu<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">da:0</span> and cpu! <span style=\"font-weight: bold\">(</span>when \n","checking argument for argument target in method wrapper__nll_loss2d_forward<span style=\"font-weight: bold\">)</span>\n","</pre>\n"],"text/plain":["\u001b[31mâ•­â”€\u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31mâ”€â•®\u001b[0m\n","\u001b[31mâ”‚\u001b[0m in \u001b[92m<module>\u001b[0m                                                                                      \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m11 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mout = out.logits      \u001b[2m#Returns a new tensor with the logit of the elements of in\u001b[0m    \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m12 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mmask_3d = mask.unsqueeze(dim=\u001b[94m2\u001b[0m).repeat_interleave(repeats=out.shape[\u001b[94m2\u001b[0m], dim=\u001b[94m2\u001b[0m)      \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m13 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mmask_out = torch.where(mask_3d == \u001b[94m1\u001b[0m, out, Sneg * torch.ones_like(out))              \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m14 \u001b[2mâ”‚   â”‚   \u001b[0mloss = criterion(mask_out.transpose(\u001b[94m2\u001b[0m, \u001b[94m1\u001b[0m), label)                                   \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m15 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[2m# í‰ê·  loss ë§Œë“¤ê¸° avg_loss[0] / avg_loss[1] <- loss ì •ê·œí™”\u001b[0m                         \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m16 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mavg_loss = loss.sum() / mask.sum()                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m17 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mavg_loss.backward()                                                                 \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[33mc:\\Users\\JIHOON\\Desktop\\study\\board\\daily_pj\\ê¹€ì§€í›ˆ\\streamlit_proj\\stream_env\\lib\\site-packages\\\u001b[0m \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[33mtorch\\nn\\modules\\module.py\u001b[0m:\u001b[94m1194\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                    \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m1194 \u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[33mc:\\Users\\JIHOON\\Desktop\\study\\board\\daily_pj\\ê¹€ì§€í›ˆ\\streamlit_proj\\stream_env\\lib\\site-packages\\\u001b[0m \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[33mtorch\\nn\\modules\\loss.py\u001b[0m:\u001b[94m1174\u001b[0m in \u001b[92mforward\u001b[0m                                                         \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m1171 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[96mself\u001b[0m.label_smoothing = label_smoothing                                            \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m1172 \u001b[0m\u001b[2mâ”‚   \u001b[0m                                                                                      \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m1173 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor, target: Tensor) -> Tensor:                           \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m1174 \u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mreturn\u001b[0m F.cross_entropy(\u001b[96minput\u001b[0m, target, weight=\u001b[96mself\u001b[0m.weight,                         \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m1175 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚      \u001b[0mignore_index=\u001b[96mself\u001b[0m.ignore_index, reduction=\u001b[96mself\u001b[0m.reduction,  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m1176 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚      \u001b[0mlabel_smoothing=\u001b[96mself\u001b[0m.label_smoothing)                      \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m1177 \u001b[0m                                                                                          \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[33mc:\\Users\\JIHOON\\Desktop\\study\\board\\daily_pj\\ê¹€ì§€í›ˆ\\streamlit_proj\\stream_env\\lib\\site-packages\\\u001b[0m \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[33mtorch\\nn\\functional.py\u001b[0m:\u001b[94m3026\u001b[0m in \u001b[92mcross_entropy\u001b[0m                                                     \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m3023 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m)                                                                                 \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m3024 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mif\u001b[0m size_average \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mor\u001b[0m reduce \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                    \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m3025 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mreduction = _Reduction.legacy_get_string(size_average, reduce)                    \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m3026 \u001b[2mâ”‚   \u001b[0m\u001b[94mreturn\u001b[0m torch._C._nn.cross_entropy_loss(\u001b[96minput\u001b[0m, target, weight, _Reduction.get_enum(re  \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m3027 \u001b[0m                                                                                          \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m3028 \u001b[0m                                                                                          \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ”‚\u001b[0m   \u001b[2m3029 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mbinary_cross_entropy\u001b[0m(                                                                 \u001b[31mâ”‚\u001b[0m\n","\u001b[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n","\u001b[1;91mRuntimeError: \u001b[0mExpected all tensors to be on the same device, but found at least two devices, cu\u001b[1;92mda:0\u001b[0m and cpu! \u001b[1m(\u001b[0mwhen \n","checking argument for argument target in method wrapper__nll_loss2d_forward\u001b[1m)\u001b[0m\n"]},"metadata":{},"output_type":"display_data"}],"source":["print (\"start\")\n","for epoch in range(epoch):\n","    print(f'{epoch}')\n","    torch.cuda.empty_cache()\n","    for batch_idx, samples in enumerate(train_dataloader):\n","        optimizer.zero_grad()\n","        token_ids, mask, label = samples\n","        token_ids = token_ids.cuda()\n","        mask = mask.cuda()\n","        label = label.cuda()\n","        out = model(token_ids)\n","        out = out.logits      #Returns a new tensor with the logit of the elements of input\n","        mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n","        mask_out = torch.where(mask_3d == 1, out, Sneg * torch.ones_like(out))\n","        loss = criterion(mask_out.transpose(2, 1), label)\n","        # í‰ê·  loss ë§Œë“¤ê¸° avg_loss[0] / avg_loss[1] <- loss ì •ê·œí™”\n","        avg_loss = loss.sum() / mask.sum()\n","        avg_loss.backward()\n","        # í•™ìŠµ ë\n","        optimizer.step()\n","print (\"end\")"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":2,"status":"aborted","timestamp":1674628371456,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"iofxgCbweLKf"},"outputs":[],"source":["torch.save(model, \"model20\")"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["model = torch.load(\".\\model20\")"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["with torch.no_grad():\n","    while 1:\n","        q = input(\"user > \").strip()\n","        if q == \"quit\":\n","            break\n","        a = \"\"\n","        while 1:\n","            input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(Q_TKN + q + SENT + A_TKN + a)).unsqueeze(dim=0)\n","            pred = model(input_ids)\n","            pred = pred.logits\n","            gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().numpy().tolist())[-1]\n","            if gen == EOS:\n","                break\n","            a += gen.replace(\"â–\", \" \")\n","        print(\"Chatbot > {}\".format(a.strip()))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNXwVr7gtq5QnQqClM4exhG","provenance":[]},"kernelspec":{"display_name":"stream_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"},"vscode":{"interpreter":{"hash":"28620e9ee99261c21df2ec0c283daac7616764567eb7af53527c6a710e77d996"}}},"nbformat":4,"nbformat_minor":0}
