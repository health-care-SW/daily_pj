{"cells":[{"cell_type":"markdown","metadata":{"id":"9Iwa3a-ydx3z"},"source":["dataset"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5955,"status":"ok","timestamp":1674628355030,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"uT_UwIOOcnCM","outputId":"3de04fc1-33b4-4daf-f8a1-07ef1c880d27"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (4.26.0)\n","Requirement already satisfied: tqdm>=4.27 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from transformers) (4.64.1)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from transformers) (23.0)\n","Requirement already satisfied: numpy>=1.17 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from transformers) (1.24.1)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from transformers) (0.11.1)\n","Requirement already satisfied: filelock in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from transformers) (3.9.0)\n","Requirement already satisfied: requests in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from transformers) (2.28.2)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from transformers) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from transformers) (0.13.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n","Requirement already satisfied: colorama in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from requests->transformers) (1.26.14)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from requests->transformers) (2.1.1)\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.2.2 -> 22.3.1\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["#pip install transformers"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":15448,"status":"ok","timestamp":1674628370476,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"_40NxplHdtg-"},"outputs":[],"source":["import math\n","import numpy as np\n","import pandas as pd\n","import random\n","import re\n","import torch\n","import urllib.request\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import PreTrainedTokenizerFast"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1674628370476,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"lajXTrUWd8YX"},"outputs":[],"source":["def collate_batch(batch):\n","    data = [item[0] for item in batch]\n","    mask = [item[1] for item in batch]\n","    label = [item[2] for item in batch]\n","    return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":229},"executionInfo":{"elapsed":716,"status":"error","timestamp":1674628371184,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"dJmzWM0Md9_P","outputId":"0ec7c7d9-16d9-4113-bfb0-71d3d7ee3e40"},"outputs":[],"source":["# train_set = ChatbotDataset(Chatbot_Data, max_len=40)\n","\n","# #ìœˆë„ìš° í™˜ê²½ì—ì„œ num_workers ëŠ” ë¬´ì¡°ê±´ 0ìœ¼ë¡œ ì§€ì •, ë¦¬ëˆ…ìŠ¤ì—ì„œëŠ” 2\n","# train_dataloader = DataLoader(train_set, batch_size=32, num_workers=0, shuffle=True, collate_fn=collate_batch,)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":3,"status":"aborted","timestamp":1674628371185,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"KCht7lKfd_BF"},"outputs":[],"source":["# print(\"start\")\n","# for batch_idx, samples in enumerate(train_dataloader):\n","#     token_ids, mask, label = samples\n","#     print(\"token_ids ====> \", token_ids)\n","#     print(\"mask =====> \", mask)\n","#     print(\"label =====> \", label)\n","# print(\"end\")"]},{"cell_type":"markdown","metadata":{"id":"X1TakpxXduqF"},"source":["kogpt"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":768,"status":"ok","timestamp":1674628417901,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"L3pAdZ2OceU3"},"outputs":[],"source":["import torch\n","from transformers import GPT2LMHeadModel"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1674628441377,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"4gK502RYdW67"},"outputs":[],"source":["Q_TKN = \"<usr>\"\n","A_TKN = \"<sys>\"\n","BOS = '</s>'\n","EOS = '</s>'\n","MASK = '<unused0>'\n","SENT = '<unused1>'\n","PAD = '<pad>'"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":653,"status":"ok","timestamp":1674628418553,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"aCgsLGQFcx7O","outputId":"c5b711ef-e3df-4c7a-de45-d9e7c14e8b8d"},"outputs":[{"name":"stderr","output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n"]},{"data":{"text/plain":["['â–ì•ˆë…•',\n"," 'í•˜',\n"," 'ì„¸',\n"," 'ìš”.',\n"," 'â–í•œêµ­ì–´',\n"," 'â–G',\n"," 'P',\n"," 'T',\n"," '-2',\n"," 'â–ì…',\n"," 'ë‹ˆë‹¤.',\n"," 'ğŸ˜¤',\n"," ':)',\n"," 'l^o']"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import PreTrainedTokenizerFast\n","tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\", bos_token='</s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>', mask_token='<mask>') \n","tokenizer.tokenize(\"ì•ˆë…•í•˜ì„¸ìš”. í•œêµ­ì–´ GPT-2 ì…ë‹ˆë‹¤.ğŸ˜¤:)l^o\")"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":4689,"status":"ok","timestamp":1674628423241,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"d9zbER_Hc7s9"},"outputs":[],"source":["model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9419,"status":"ok","timestamp":1674628432658,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"hx20-h_idEpt","outputId":"f5fb3fdc-c4a5-4c97-f241-e7ed5fdf84c8"},"outputs":[{"name":"stdout","output_type":"stream","text":["ìš´ë™ í•˜ë ¤ê³  í•˜ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤.\n","ê·¸ëŸ°ë° ì´ê²Œ ì§€ê¸ˆ í˜„ì¬ë¡œì„œëŠ” êµ‰ì¥íˆ ì–´ë ¤ìš´ ìƒí™©ì…ë‹ˆë‹¤.\n","ì™œëƒí•˜ë©´ ê·¸~ ì €í¬ê°€ ì´ì œ ë­ ì—¬ëŸ¬ ê°€ì§€ ì–˜ê¸°ë¥¼ í•˜ê³  ìˆëŠ”ë°ìš”.\n","ì´ì œ ìš°ë¦¬ êµ­ë¯¼ë“¤ì´ ê°€ì¥ ë§ì´ ê±±ì •í•˜ëŠ” ê²Œ ë°”ë¡œ ì´ëŸ° ê²ƒë“¤ì´ê±°ë“ ìš”?\n","ë„¤. ê·¸ë˜ì„œ ìš°ë¦¬ê°€ ì¢€ ë” ì ê·¹ì ìœ¼ë¡œ ë‚˜ì„œì•¼ ë  í•„ìš”ê°€ ìˆë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤.\n","ì˜ˆ. ì ì˜¤ëŠ˜ ë§ì”€ ì—¬ê¸°ê¹Œì§€ ë“£ê² ìŠµë‹ˆë‹¤. ê³ ë§™ê³ ìš”\n","ê°ì‚¬í•©ë‹ˆë‹¤.</d> ë„¤ ì•ˆë…•í•˜ì‹­ë‹ˆê¹Œ?\n","ì‹œì‚¬íƒ±í¬ì— ì¥ì„±ë¯¼ ì…ë‹ˆë‹¤.\n","ì˜¤ëŠ˜ì€ ì–´ë–¤ ì†Œì‹ë“¤ ì¤€ë¹„í–ˆìŠµë‹ˆê¹Œ.\n","ë¨¼ì € ë°•ê·¼í˜œ ëŒ€í†µë ¹ì´ ì–´ì œ ì²­ì™€ëŒ€ì—ì„œ ì—´ë¦° êµ­ë¬´íšŒì˜ì—ì„œ ì„¸ì›”í˜¸ ì°¸ì‚¬ì— ëŒ€í•œ ëŒ€êµ­ë¯¼ ì‚¬ê³¼ë¥¼ í–ˆì£ .\n","\n"]}],"source":["text = 'ìš´ë™ í•˜ë ¤ê³ '\n","input_ids = tokenizer.encode(text)\n","gen_ids = model.generate(torch.tensor([input_ids]),\n","                           max_length=128,\n","                           repetition_penalty=2.0,\n","                           pad_token_id=tokenizer.pad_token_id,\n","                           eos_token_id=tokenizer.eos_token_id,\n","                           bos_token_id=tokenizer.bos_token_id,\n","                           use_cache=True)\n","generated = tokenizer.decode(gen_ids[0,:].tolist())\n","print(generated)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4701,"status":"ok","timestamp":1674628437350,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"G5NKrWHCdQRZ","outputId":"1f9fe5e9-0d50-4a6b-b475-d857525dabe4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pytorch_lightning in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (1.9.0)\n","Requirement already satisfied: tqdm>=4.57.0 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from pytorch_lightning) (4.64.1)\n","Requirement already satisfied: PyYAML>=5.4 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from pytorch_lightning) (6.0)\n","Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from pytorch_lightning) (4.4.0)\n","Requirement already satisfied: torchmetrics>=0.7.0 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from pytorch_lightning) (0.11.0)\n","Requirement already satisfied: packaging>=17.1 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from pytorch_lightning) (23.0)\n","Requirement already satisfied: numpy>=1.17.2 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from pytorch_lightning) (1.24.1)\n","Requirement already satisfied: torch>=1.10.0 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from pytorch_lightning) (1.13.1)\n","Requirement already satisfied: lightning-utilities>=0.4.2 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from pytorch_lightning) (0.6.0.post0)\n","Requirement already satisfied: fsspec[http]>2021.06.0 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from pytorch_lightning) (2023.1.0)\n","Requirement already satisfied: requests in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.28.2)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.3)\n","Requirement already satisfied: colorama in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from tqdm>=4.57.0->pytorch_lightning) (0.4.6)\n","Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.1.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.3)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.8.2)\n","Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (22.2.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.26.14)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jihoon\\desktop\\healthcare\\streamlit_proj\\streamlit_env\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.4)\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.2.2 -> 22.3.1\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["\n","#pip install pytorch_lightning"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":1454,"status":"ok","timestamp":1674628440102,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"eg_3RlbBdIDG"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","from pytorch_lightning import Trainer\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","#from pytorch_lightning.core.lightning import LightningModule\n","from torch.utils.data import DataLoader, Dataset\n","from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n","from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n","import re"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5515,"status":"ok","timestamp":1674628447821,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"ypPMx3CNdYat","outputId":"df83f7be-89f8-497c-8dca-cd64c62b8922"},"outputs":[{"name":"stderr","output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n"]}],"source":["koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n","            bos_token=BOS, eos_token=EOS, unk_token='<unk>',\n","            pad_token=PAD, mask_token=MASK) \n","model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":700,"status":"ok","timestamp":1674628449583,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"jvei2sXLdZkZ","outputId":"b1dfacc5-3136-433e-9da6-46595a7e5e6c"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Q</th>\n","      <th>A</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12ì‹œ ë•¡!</td>\n","      <td>í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´</td>\n","      <td>ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤</td>\n","      <td>ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤</td>\n","      <td>ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>PPL ì‹¬í•˜ë„¤</td>\n","      <td>ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 Q            A  label\n","0           12ì‹œ ë•¡!   í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.      0\n","1      1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´    ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.      0\n","2     3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤  ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .      0\n","3  3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤  ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .      0\n","4          PPL ì‹¬í•˜ë„¤   ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .      0"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["import urllib.request\n","\n","urllib.request.urlretrieve(\n","    \"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\",\n","    filename=\"ChatBotData.csv\",\n",")\n","Chatbot_Data = pd.read_csv(\"ChatBotData.csv\")\n","# Test ìš©ìœ¼ë¡œ 300ê°œ ë°ì´í„°ë§Œ ì²˜ë¦¬í•œë‹¤.\n","Chatbot_Data = Chatbot_Data[:300]\n","Chatbot_Data.head()"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1674628370476,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"z-HwxfJJd2Pr"},"outputs":[],"source":["class ChatbotDataset(Dataset):\n","    def __init__(self, chats, max_len=40):  # ë°ì´í„°ì…‹ì˜ ì „ì²˜ë¦¬ë¥¼ í•´ì£¼ëŠ” ë¶€ë¶„\n","        self._data = chats\n","        self.max_len = max_len\n","        self.q_token = Q_TKN\n","        self.a_token = A_TKN\n","        self.sent_token = SENT\n","        self.eos = EOS\n","        self.mask = MASK\n","        self.tokenizer = koGPT2_TOKENIZER\n","\n","    def __len__(self):  # chatbotdata ì˜ ê¸¸ì´ë¥¼ ë¦¬í„´í•œë‹¤.\n","        return len(self._data)\n","\n","    def __getitem__(self, idx):  # ë¡œë“œí•œ ì±—ë´‡ ë°ì´í„°ë¥¼ ì°¨ë¡€ì°¨ë¡€ DataLoaderë¡œ ë„˜ê²¨ì£¼ëŠ” ë©”ì„œë“œ\n","        turn = self._data.iloc[idx]\n","        q = turn[\"Q\"]  # ì§ˆë¬¸ì„ ê°€ì ¸ì˜¨ë‹¤.\n","        q = re.sub(r\"([?.!,])\", r\" \", q)  # êµ¬ë‘£ì ë“¤ì„ ì œê±°í•œë‹¤.\n","\n","        a = turn[\"A\"]  # ë‹µë³€ì„ ê°€ì ¸ì˜¨ë‹¤.\n","        a = re.sub(r\"([?.!,])\", r\" \", a)  # êµ¬ë‘£ì ë“¤ì„ ì œê±°í•œë‹¤.\n","\n","        q_toked = self.tokenizer.tokenize(self.q_token + q + self.sent_token)\n","        q_len = len(q_toked)\n","\n","        a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos)\n","        a_len = len(a_toked)\n","\n","        #ì§ˆë¬¸ì˜ ê¸¸ì´ê°€ ìµœëŒ€ê¸¸ì´ë³´ë‹¤ í¬ë©´\n","        if q_len > self.max_len:\n","            a_len = self.max_len - q_len        #ë‹µë³€ì˜ ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ - ì§ˆë¬¸ê¸¸ì´\n","            if a_len <= 0:       #ì§ˆë¬¸ì˜ ê¸¸ì´ê°€ ë„ˆë¬´ ê¸¸ì–´ ì§ˆë¬¸ë§Œìœ¼ë¡œ ìµœëŒ€ ê¸¸ì´ë¥¼ ì´ˆê³¼ í•œë‹¤ë©´\n","                q_toked = q_toked[-(int(self.max_len / 2)) :]   #ì§ˆë¬¸ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ì˜ ë°˜ìœ¼ë¡œ \n","                q_len = len(q_toked)\n","                a_len = self.max_len - q_len              #ë‹µë³€ì˜ ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ - ì§ˆë¬¸ê¸¸ì´\n","            a_toked = a_toked[:a_len]\n","            a_len = len(a_toked)\n","\n","        #ì§ˆë¬¸ì˜ ê¸¸ì´ + ë‹µë³€ì˜ ê¸¸ì´ê°€ ìµœëŒ€ê¸¸ì´ë³´ë‹¤ í¬ë©´\n","        if q_len + a_len > self.max_len:\n","            a_len = self.max_len - q_len        #ë‹µë³€ì˜ ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ - ì§ˆë¬¸ê¸¸ì´\n","            if a_len <= 0:       #ì§ˆë¬¸ì˜ ê¸¸ì´ê°€ ë„ˆë¬´ ê¸¸ì–´ ì§ˆë¬¸ë§Œìœ¼ë¡œ ìµœëŒ€ ê¸¸ì´ë¥¼ ì´ˆê³¼ í•œë‹¤ë©´\n","                q_toked = q_toked[-(int(self.max_len / 2)) :]   #ì§ˆë¬¸ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ì˜ ë°˜ìœ¼ë¡œ \n","                q_len = len(q_toked)\n","                a_len = self.max_len - q_len              #ë‹µë³€ì˜ ê¸¸ì´ë¥¼ ìµœëŒ€ê¸¸ì´ - ì§ˆë¬¸ê¸¸ì´\n","            a_toked = a_toked[:a_len]\n","            a_len = len(a_toked)\n","\n","        # ë‹µë³€ labels = [mask, mask, ...., mask, ..., <bos>,..ë‹µë³€.. <eos>, <pad>....]\n","        labels = [self.mask,] * q_len + a_toked[1:]\n","\n","        # mask = ì§ˆë¬¸ê¸¸ì´ 0 + ë‹µë³€ê¸¸ì´ 1 + ë‚˜ë¨¸ì§€ 0\n","        mask = [0] * q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len)\n","        # ë‹µë³€ labelsì„ index ë¡œ ë§Œë“ ë‹¤.\n","        labels_ids = self.tokenizer.convert_tokens_to_ids(labels)\n","        # ìµœëŒ€ê¸¸ì´ë§Œí¼ PADDING\n","        while len(labels_ids) < self.max_len:\n","            labels_ids += [self.tokenizer.pad_token_id]\n","\n","        # ì§ˆë¬¸ + ë‹µë³€ì„ index ë¡œ ë§Œë“ ë‹¤.    \n","        token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\n","        # ìµœëŒ€ê¸¸ì´ë§Œí¼ PADDING\n","        while len(token_ids) < self.max_len:\n","            token_ids += [self.tokenizer.pad_token_id]\n","\n","        #ì§ˆë¬¸+ë‹µë³€, ë§ˆìŠ¤í¬, ë‹µë³€\n","        return (token_ids, np.array(mask), labels_ids)"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":358,"status":"ok","timestamp":1674628452783,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"EYC4Pg-fddnz"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","train_set = ChatbotDataset(Chatbot_Data, max_len=40)\n","#ìœˆë„ìš° í™˜ê²½ì—ì„œ num_workers ëŠ” ë¬´ì¡°ê±´ 0ìœ¼ë¡œ ì§€ì •, ë¦¬ëˆ…ìŠ¤ì—ì„œëŠ” 2\n","train_dataloader = DataLoader(train_set, batch_size=32, num_workers=0, shuffle=True, collate_fn=collate_batch,)"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":273,"status":"ok","timestamp":1674628454060,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"9GsK1EGgeE3N","outputId":"147b9bc8-5c83-4c78-f54e-cb0b98c71552"},"outputs":[{"data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(51200, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",")"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["model.to(device)\n","model.train()"]},{"cell_type":"code","execution_count":53,"metadata":{"executionInfo":{"elapsed":246,"status":"ok","timestamp":1674628456507,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"UBwTSr5ReGf-"},"outputs":[],"source":["learning_rate = 3e-5\n","criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","epoch = 10\n","Sneg = -1e18"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lLj6pkbIeJH0","outputId":"ef7376a3-8970-471e-eb36-c5302292b15d"},"outputs":[],"source":["print (\"start\")\n","for epoch in range(epoch):\n","    print(f'{epoch}')\n","    for batch_idx, samples in enumerate(train_dataloader):\n","        optimizer.zero_grad()\n","        token_ids, mask, label = samples\n","        out = model(token_ids)\n","        out = out.logits      #Returns a new tensor with the logit of the elements of input\n","        mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n","        mask_out = torch.where(mask_3d == 1, out, Sneg * torch.ones_like(out))\n","        loss = criterion(mask_out.transpose(2, 1), label)\n","        # í‰ê·  loss ë§Œë“¤ê¸° avg_loss[0] / avg_loss[1] <- loss ì •ê·œí™”\n","        avg_loss = loss.sum() / mask.sum()\n","        avg_loss.backward()\n","        # í•™ìŠµ ë\n","        optimizer.step()\n","print (\"end\")"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":2,"status":"aborted","timestamp":1674628371456,"user":{"displayName":"ê¹€ì§€í›ˆ","userId":"08130216737598451536"},"user_tz":-540},"id":"iofxgCbweLKf"},"outputs":[],"source":["torch.save(model, \"model\")"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n","model = torch.load(\".\\model\")"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"],"text/plain":[]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"],"text/plain":[]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"],"text/plain":[]},"metadata":{},"output_type":"display_data"}],"source":["with torch.no_grad():\n","    while 1:\n","        q = input(\"user > \").strip()\n","        if q == \"quit\":\n","            break\n","        a = \"\"\n","        while 1:\n","            input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(Q_TKN + q + SENT + A_TKN + a)).unsqueeze(dim=0)\n","            pred = model(input_ids)\n","            pred = pred.logits\n","            gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().numpy().tolist())[-1]\n","            if gen == EOS:\n","                break\n","            a += gen.replace(\"â–\", \" \")\n","        print(\"Chatbot > {}\".format(a.strip()))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNXwVr7gtq5QnQqClM4exhG","provenance":[]},"kernelspec":{"display_name":"streamlit_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"},"vscode":{"interpreter":{"hash":"78d073b1e51fd0fd63c674299ec5005863bf2a675fa0a567fed343fdccac1e04"}}},"nbformat":4,"nbformat_minor":0}
